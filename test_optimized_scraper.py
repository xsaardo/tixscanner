#!/usr/bin/env python3
"""
Test the optimized Ticketmaster scraper with section targeting.
"""

import sys
import json
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.optimized_scraper import TicketmasterOptimizedScraper

def test_optimized_scraper():
    """Test the optimized scraper with section targeting."""
    
    print("ğŸ¯ Testing Optimized Ticketmaster Scraper with Section Targeting")
    print("=" * 70)
    
    # Backstreet Boys event URL
    event_url = "https://www.ticketmaster.com/backstreet-boys-into-the-millennium-las-vegas-nevada-12-26-2025/event/1700630C79D40EAD"
    
    print(f"ğŸµ Event: Backstreet Boys at The Sphere")
    print(f"ğŸ”— URL: {event_url}")
    print()
    
    with TicketmasterOptimizedScraper(headless=True) as scraper:
        
        # Test 1: Get all sections
        print("1ï¸âƒ£ Testing: All Sections")
        print("-" * 30)
        
        all_results = scraper.scrape_section_pricing(event_url)
        
        if all_results['success']:
            print(f"âœ… Found {all_results['total_prices']} total prices")
            print(f"ğŸ’° Overall range: ${all_results['min_price']:.2f} - ${all_results['max_price']:.2f}")
            print(f"ğŸ­ Sections found: {len(all_results['sections'])}")
            
            for section_name, section_data in all_results['sections'].items():
                price_count = len(section_data['prices'])
                min_price = section_data['min_price']
                max_price = section_data['max_price']
                avg_price = section_data['avg_price']
                
                print(f"   ğŸ“ {section_name}: {price_count} prices, ${min_price:.2f}-${max_price:.2f} (avg: ${avg_price:.2f})")
        else:
            print(f"âŒ Failed: {all_results.get('error')}")
        
        print()
        
        # Test 2: Target General Admission specifically
        print("2ï¸âƒ£ Testing: General Admission Only")
        print("-" * 30)
        
        ga_results = scraper.get_general_admission_prices(event_url)
        
        if ga_results['success']:
            print(f"âœ… General Admission targeting successful")
            print(f"ğŸ« Sections matched: {list(ga_results['sections'].keys())}")
            
            for section_name, section_data in ga_results['sections'].items():
                prices = section_data['prices']
                print(f"   ğŸ“ {section_name}:")
                print(f"      â€¢ Price count: {len(prices)}")
                print(f"      â€¢ Price range: ${section_data['min_price']:.2f} - ${section_data['max_price']:.2f}")
                print(f"      â€¢ Average price: ${section_data['avg_price']:.2f}")
                
                # Show sample prices
                sample_prices = [p['price'] for p in prices[:5]]
                print(f"      â€¢ Sample prices: {[f'${p:.2f}' for p in sample_prices]}")
                
                # Show element context for first few prices
                print(f"      â€¢ Element context samples:")
                for i, price_data in enumerate(prices[:3]):
                    context = price_data['element_text'][:50] + "..." if len(price_data['element_text']) > 50 else price_data['element_text']
                    print(f"        {i+1}. ${price_data['price']:.2f} - \"{context}\"")
        else:
            print(f"âŒ No General Admission prices found")
            if ga_results.get('sections'):
                print("Available sections:")
                for section in ga_results['sections'].keys():
                    print(f"   â€¢ {section}")
        
        print()
        
        # Test 3: Target specific sections with variations
        print("3ï¸âƒ£ Testing: Multiple Target Sections")
        print("-" * 30)
        
        target_sections = ["General Admission", "Floor", "VIP", "Premium"]
        multi_results = scraper.scrape_section_pricing(event_url, target_sections=target_sections)
        
        if multi_results['success']:
            print(f"âœ… Multi-section targeting successful")
            print(f"ğŸ¯ Targeted: {target_sections}")
            print(f"ğŸ“ Found: {list(multi_results['sections'].keys())}")
            
            for section_name, section_data in multi_results['sections'].items():
                price_count = len(section_data['prices'])
                price_range = f"${section_data['min_price']:.2f}-${section_data['max_price']:.2f}"
                print(f"   â€¢ {section_name}: {price_count} prices ({price_range})")
        else:
            print(f"âŒ No matching sections found for: {target_sections}")
        
        print()
        
        # Performance comparison
        print("4ï¸âƒ£ Performance Analysis")
        print("-" * 30)
        
        if all_results['success']:
            total_elements_processed = sum(len(section['prices']) for section in all_results['sections'].values())
            unique_sections = len(all_results['sections'])
            
            print(f"ğŸ“Š Extraction Statistics:")
            print(f"   â€¢ Total price elements processed: {total_elements_processed}")
            print(f"   â€¢ Unique sections identified: {unique_sections}")
            print(f"   â€¢ Section identification accuracy: {(unique_sections > 1) and 'âœ… Good' or 'âš ï¸ Limited'}")
            print(f"   â€¢ Price range coverage: ${all_results['min_price']:.2f} - ${all_results['max_price']:.2f}")
            
            print(f"\nğŸš€ Optimization Benefits:")
            print(f"   âœ… Focused extraction (element selectors only)")
            print(f"   âœ… Section-specific targeting capability")
            print(f"   âœ… Reduced processing overhead")
            print(f"   âœ… Better context preservation")
            
        print()
        print("ğŸ‰ Optimized scraper testing completed!")

def test_section_matching():
    """Test section matching logic separately."""
    
    print("\nğŸ§ª Testing Section Matching Logic")
    print("-" * 40)
    
    with TicketmasterOptimizedScraper() as scraper:
        # Test various section name variations
        test_cases = [
            ("General Admission", ["General Admission"], True),
            ("GA Floor", ["General Admission"], True), 
            ("General", ["General Admission"], True),
            ("Section 101", ["General Admission"], False),
            ("Floor VIP", ["VIP"], True),
            ("Premium Seating", ["Premium"], True),
        ]
        
        print("Section matching test cases:")
        for section_name, targets, expected in test_cases:
            result = scraper._matches_target_section(section_name, targets)
            status = "âœ…" if result == expected else "âŒ"
            print(f"   {status} '{section_name}' matches {targets}: {result} (expected: {expected})")

if __name__ == "__main__":
    test_optimized_scraper()
    test_section_matching()